{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+hOztj7qUhJtF5vN2K4MM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Linear Quadratic Regulator Control Example\n","with reference from [automaticaddison.com](https://automaticaddison.com/linear-quadratic-regulator-lqr-with-python-code-example/)\n","\n"],"metadata":{"id":"rXqDyOrMl-yt"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3wK-VlOl49X","executionInfo":{"status":"ok","timestamp":1673621237819,"user_tz":-480,"elapsed":19,"user":{"displayName":"Muhammad Zharfan Wiranata","userId":"06540908194621854514"}},"outputId":"8ce7c57e-4b06-4437-f57f-25080d6c5115"},"outputs":[{"output_type":"stream","name":"stdout","text":["iteration = 0 seconds\n","Current State = [0 0 0]\n","Desired State = [2.    2.    1.571]\n","State Error Magnitude = 3.2353363194994644\n","Control Input = [1.969 1.555]\n","\n","iteration = 1 seconds\n","Current State = [1.969 0.    1.555]\n","Desired State = [2.    2.    1.571]\n","State Error Magnitude = 2.0002978637484863\n","Control Input = [1.98  0.015]\n","\n","iteration = 2 seconds\n","Current State = [2.    1.98  1.571]\n","Desired State = [2.    2.    1.571]\n","State Error Magnitude = 0.019807158896646308\n","Control Input = [0.02 0.  ]\n","\n","iteration = 3 seconds\n","Current State = [2.    2.    1.571]\n","Desired State = [2.    2.    1.571]\n","State Error Magnitude = 0.00019662973052900144\n","Control Input = [0. 0.]\n","\n","Goal Has Been Reached Successfully!\n"]}],"source":["import numpy as np\n"," \n","# Author: Addison Sears-Collins\n","# https://automaticaddison.com\n","# Description: Linear Quadratic Regulator example \n","#   (two-wheeled differential drive robot car)\n"," \n","######################## DEFINE CONSTANTS #####################################\n","# Supress scientific notation when printing NumPy arrays\n","np.set_printoptions(precision=3,suppress=True)\n"," \n","# Optional Variables\n","max_linear_velocity = 3.0 # meters per second\n","max_angular_velocity = 1.5708 # radians per second\n"," \n","def getB(yaw, deltat):\n","    \"\"\"\n","    Calculates and returns the B matrix\n","    3x2 matix ---> number of states x number of control inputs\n"," \n","    Expresses how the state of the system [x,y,yaw] changes\n","    from t-1 to t due to the control commands (i.e. control inputs).\n","     \n","    :param yaw: The yaw angle (rotation angle around the z axis) in radians \n","    :param deltat: The change in time from timestep t-1 to t in seconds\n","     \n","    :return: B matrix ---> 3x2 NumPy array\n","    \"\"\"\n","    B = np.array([  [np.cos(yaw)*deltat, 0],\n","                                    [np.sin(yaw)*deltat, 0],\n","                                    [0, deltat]])\n","    return B\n"," \n"," \n","def state_space_model(A, state_t_minus_1, B, control_input_t_minus_1):\n","    \"\"\"\n","    Calculates the state at time t given the state at time t-1 and\n","    the control inputs applied at time t-1\n","     \n","    :param: A   The A state transition matrix\n","        3x3 NumPy Array\n","    :param: state_t_minus_1     The state at time t-1  \n","        3x1 NumPy Array given the state is [x,y,yaw angle] ---> \n","        [meters, meters, radians]\n","    :param: B   The B state transition matrix\n","        3x2 NumPy Array\n","    :param: control_input_t_minus_1     Optimal control inputs at time t-1  \n","        2x1 NumPy Array given the control input vector is \n","        [linear velocity of the car, angular velocity of the car]\n","        [meters per second, radians per second]\n","         \n","    :return: State estimate at time t\n","        3x1 NumPy Array given the state is [x,y,yaw angle] --->\n","        [meters, meters, radians]\n","    \"\"\"\n","    # These next 6 lines of code which place limits on the angular and linear \n","    # velocities of the robot car can be removed if you desire.\n","    control_input_t_minus_1[0] = np.clip(control_input_t_minus_1[0],\n","                                                                            -max_linear_velocity,\n","                                                                            max_linear_velocity)\n","    control_input_t_minus_1[1] = np.clip(control_input_t_minus_1[1],\n","                                                                            -max_angular_velocity,\n","                                                                            max_angular_velocity)\n","    state_estimate_t = (A @ state_t_minus_1) + (B @ control_input_t_minus_1) \n","             \n","    return state_estimate_t\n","     \n","def lqr(actual_state_x, desired_state_xf, Q, R, A, B, dt):\n","    \"\"\"\n","    Discrete-time linear quadratic regulator for a nonlinear system.\n"," \n","    Compute the optimal control inputs given a nonlinear system, cost matrices, \n","    current state, and a final state.\n","     \n","    Compute the control variables that minimize the cumulative cost.\n"," \n","    Solve for P using the dynamic programming method.\n"," \n","    :param actual_state_x: The current state of the system \n","        3x1 NumPy Array given the state is [x,y,yaw angle] --->\n","        [meters, meters, radians]\n","    :param desired_state_xf: The desired state of the system\n","        3x1 NumPy Array given the state is [x,y,yaw angle] --->\n","        [meters, meters, radians]   \n","    :param Q: The state cost matrix\n","        3x3 NumPy Array\n","    :param R: The input cost matrix\n","        2x2 NumPy Array\n","    :param dt: The size of the timestep in seconds -> float\n"," \n","    :return: u_star: Optimal action u for the current state \n","        2x1 NumPy Array given the control input vector is\n","        [linear velocity of the car, angular velocity of the car]\n","        [meters per second, radians per second]\n","    \"\"\"\n","    # We want the system to stabilize at desired_state_xf.\n","    x_error = actual_state_x - desired_state_xf\n"," \n","    # Solutions to discrete LQR problems are obtained using the dynamic \n","    # programming method.\n","    # The optimal solution is obtained recursively, starting at the last \n","    # timestep and working backwards.\n","    # You can play with this number\n","    N = 50\n"," \n","    # Create a list of N + 1 elements\n","    P = [None] * (N + 1)\n","     \n","    Qf = Q\n"," \n","    # LQR via Dynamic Programming\n","    P[N] = Qf\n"," \n","    # For i = N, ..., 1\n","    for i in range(N, 0, -1):\n"," \n","        # Discrete-time Algebraic Riccati equation to calculate the optimal \n","        # state cost matrix\n","        P[i-1] = Q + A.T @ P[i] @ A - (A.T @ P[i] @ B) @ np.linalg.pinv(\n","            R + B.T @ P[i] @ B) @ (B.T @ P[i] @ A)      \n"," \n","    # Create a list of N elements\n","    K = [None] * N\n","    u = [None] * N\n"," \n","    # For i = 0, ..., N - 1\n","    for i in range(N):\n"," \n","        # Calculate the optimal feedback gain K\n","        K[i] = -np.linalg.pinv(R + B.T @ P[i+1] @ B) @ B.T @ P[i+1] @ A\n"," \n","        u[i] = K[i] @ x_error\n"," \n","    # Optimal control input is u_star\n","    u_star = u[N-1]\n"," \n","    return u_star\n"," \n","def main():\n","     \n","    # Let the time interval be 1.0 seconds\n","    dt = 1.0\n","     \n","    # Actual state\n","    # Our robot starts out at the origin (x=0 meters, y=0 meters), and \n","    # the yaw angle is 0 radians. \n","    actual_state_x = np.array([0,0,0]) \n"," \n","    # Desired state [x,y,yaw angle]\n","    # [meters, meters, radians]\n","    desired_state_xf = np.array([2.000,2.000,np.pi/2])  \n","     \n","    # A matrix\n","    # 3x3 matrix -> number of states x number of states matrix\n","    # Expresses how the state of the system [x,y,yaw] changes \n","    # from t-1 to t when no control command is executed.\n","    # Typically a robot on wheels only drives when the wheels are told to turn.\n","    # For this case, A is the identity matrix.\n","    # Note: A is sometimes F in the literature.\n","    A = np.array([  [1.0,  0,   0],\n","                                    [  0,1.0,   0],\n","                                    [  0,  0, 1.0]])\n"," \n","    # R matrix\n","    # The control input cost matrix\n","    # Experiment with different R matrices\n","    # This matrix penalizes actuator effort (i.e. rotation of the \n","    # motors on the wheels that drive the linear velocity and angular velocity).\n","    # The R matrix has the same number of rows as the number of control\n","    # inputs and same number of columns as the number of \n","    # control inputs.\n","    # This matrix has positive values along the diagonal and 0s elsewhere.\n","    # We can target control inputs where we want low actuator effort \n","    # by making the corresponding value of R large. \n","    R = np.array([[0.01,   0],  # Penalty for linear velocity effort\n","                [  0, 0.01]]) # Penalty for angular velocity effort\n"," \n","    # Q matrix\n","    # The state cost matrix.\n","    # Experiment with different Q matrices.\n","    # Q helps us weigh the relative importance of each state in the \n","    # state vector (X, Y, YAW ANGLE). \n","    # Q is a square matrix that has the same number of rows as \n","    # there are states.\n","    # Q penalizes bad performance.\n","    # Q has positive values along the diagonal and zeros elsewhere.\n","    # Q enables us to target states where we want low error by making the \n","    # corresponding value of Q large.\n","    Q = np.array([[0.639, 0, 0],  # Penalize X position error \n","                                [0, 1.0, 0],  # Penalize Y position error \n","                                [0, 0, 1.0]]) # Penalize YAW ANGLE heading error \n","                   \n","    # Launch the robot, and have it move to the desired goal destination\n","    for i in range(100):\n","        print(f'iteration = {i} seconds')\n","        print(f'Current State = {actual_state_x}')\n","        print(f'Desired State = {desired_state_xf}')\n","         \n","        state_error = actual_state_x - desired_state_xf\n","        state_error_magnitude = np.linalg.norm(state_error)     \n","        print(f'State Error Magnitude = {state_error_magnitude}')\n","         \n","        B = getB(actual_state_x[2], dt)\n","         \n","        # LQR returns the optimal control input\n","        optimal_control_input = lqr(actual_state_x, \n","                                    desired_state_xf, \n","                                    Q, R, A, B, dt) \n","         \n","        print(f'Control Input = {optimal_control_input}')\n","                                     \n","         \n","        # We apply the optimal control to the robot\n","        # so we can get a new actual (estimated) state.\n","        actual_state_x = state_space_model(A, actual_state_x, B, \n","                                        optimal_control_input)  \n"," \n","        # Stop as soon as we reach the goal\n","        # Feel free to change this threshold value.\n","        if state_error_magnitude < 0.01:\n","            print(\"\\nGoal Has Been Reached Successfully!\")\n","            break\n","             \n","        print()\n"," \n","# Entry point for the program\n","main()"]}]}